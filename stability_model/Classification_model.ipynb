{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb531254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "import numpy as np\n",
    "\n",
    "def get_esm_embeddings(sequences):\n",
    "\n",
    "    model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    model.eval()\n",
    "\n",
    "    data = [('protein'+str(i), seq) for i, seq in enumerate(sequences)]\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "\n",
    "    token_embeddings = results[\"representations\"][33]\n",
    "\n",
    "    sequence_embeddings = []\n",
    "    for i in range(len(sequences)):\n",
    "        seq_len = len(sequences[i])\n",
    "        seq_emb = token_embeddings[i, 1:1+seq_len]\n",
    "        sequence_embeddings.append(seq_emb.cpu().numpy())\n",
    "    return sequence_embeddings\n",
    "\n",
    "def embed_and_pool(sequences):\n",
    "    seq_emb_list = get_esm_embeddings(sequences)\n",
    "    pooled_list = []\n",
    "    for emb in seq_emb_list:\n",
    "        pooled_vec = emb.mean(axis=0) \n",
    "        pooled_list.append(pooled_vec)\n",
    "    return np.array(pooled_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d15ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            self.X = torch.from_numpy(X).float()\n",
    "        else:\n",
    "            self.X = X.float()\n",
    "        \n",
    "        self.y = None\n",
    "        if y is not None:\n",
    "            if isinstance(y, np.ndarray):\n",
    "                self.y = torch.from_numpy(y).long() \n",
    "            else:\n",
    "                self.y = y.long()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.X[idx], self.y[idx]\n",
    "        else:\n",
    "            return self.X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3507248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[512,256,128,64], num_classes=2):\n",
    "        \"\"\"\n",
    "        hidden_dims: 例如 [512,256,128,64]\n",
    "        \"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_dim = h\n",
    "        layers.append(nn.Linear(prev_dim, num_classes)) \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def cross_val_score_mlp(X, y, \n",
    "                        hidden_dims,\n",
    "                        lr,\n",
    "                        batch_size,\n",
    "                        device,\n",
    "                        n_splits=5,\n",
    "                        max_epochs=30,\n",
    "                        patience=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    auc_scores = []\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        train_dataset = ProteinDataset(X_train, y_train)\n",
    "        val_dataset = ProteinDataset(X_val, y_val)\n",
    "        \n",
    "        class_sample_counts = np.bincount(y_train) \n",
    "        weights_per_class = 1.0 / (class_sample_counts + 1e-8)\n",
    "        samples_weight = weights_per_class[y_train] \n",
    "        \n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=samples_weight, \n",
    "            num_samples=len(samples_weight), \n",
    "            replacement=True\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        input_dim = X.shape[1]\n",
    "        model = MLP(input_dim, hidden_dims=hidden_dims, num_classes=2).to(device)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss() \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        best_auc = 0.0\n",
    "        best_state = None\n",
    "        epochs_no_improve = 0\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            model.train()\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            model.eval()\n",
    "            val_probs = []\n",
    "            val_targets = []\n",
    "            with torch.no_grad():\n",
    "                for batch_x, batch_y in val_loader:\n",
    "                    batch_x = batch_x.to(device)\n",
    "                    outputs = model(batch_x)\n",
    "                    probs = torch.softmax(outputs, dim=1)[:,1] \n",
    "                    val_probs.extend(probs.cpu().numpy())\n",
    "                    val_targets.extend(batch_y.numpy())\n",
    "            \n",
    "            val_auc = roc_auc_score(val_targets, val_probs)\n",
    "            \n",
    "            if val_auc > best_auc:\n",
    "                best_auc = val_auc\n",
    "                best_state = model.state_dict()\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "            \n",
    "            if epochs_no_improve >= patience:\n",
    "                break\n",
    "        \n",
    "        auc_scores.append(best_auc)\n",
    "    \n",
    "    return np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    hidden_dims = []\n",
    "    for i in range(4):\n",
    "        hidden_dim = trial.suggest_int(f\"hidden_dim_{i}\", 64, 512, step=64)\n",
    "        hidden_dims.append(hidden_dim)\n",
    "    \n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    \n",
    "    mean_auc = cross_val_score_mlp(\n",
    "        X_trainval, y_trainval,\n",
    "        hidden_dims=hidden_dims,\n",
    "        lr=lr,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "        n_splits=5,\n",
    "        max_epochs=30,   \n",
    "        patience=5\n",
    "    )\n",
    "    \n",
    "    return mean_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab5cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv(\"./Classification_train_data.csv\")\n",
    "sequences = df[\"protein_sequence\"].tolist()\n",
    "labels = df[\"experimental_stability_group\"].tolist()\n",
    "X = embed_and_pool(sequences)\n",
    "y = np.array(labels)\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20) \n",
    "print(\"Best trial:\", study.best_trial.value)\n",
    "print(\"Best params:\", study.best_trial.params)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
